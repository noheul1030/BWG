< 2023.08.18 >

- 논리모델과 물리모델의 차이
- 테이블 레이아웃은 물리모델의 결과물
- VARCHAR2 : 오라클에 있는 데이터타입
- 데이터 모델러가 제일 싫어하는 것? : NULL과 데이터의 중복~

- 논리모델에서 물리모델로 넘어갈 때에 성능을 고려하여
	- 서브타입 모델의 변화
	- 엔티티 합체와 분해
	- 비정규화
	- PK확정
	- 테이블 파티션 확정 : 일(day)단위로 파티션을 설정할 수도 있다.
	- 데이터 저장방법 확정
	- 인덱스 설계
	- 뷰 설계 
	- 시스템 속성 추가
	- dbms : 데이터를 적재하는 방식(가장 최근에 쌓인 데이터의 성능을 높인다.)
	- JOIN 되는 2개의 테이블을 굳이 하나로 합쳐서 만들지 않는 이유는 데이터의 관점에서는 모델의 엔티티를 분리해서 관리하는 것이 낫기 떄문에,
	  view라는 테이블을 만들어서 두개의 테이블을 합쳐지는 결과물로 보여지게 해서 편의성,실용성을 높인다.
	  예) 뷰에서 select * from view 쿼리문을 작성 하면 실제 물리적인 테이블은 2개이지만,
		 용도에 따라 가상의 테이블에 합쳐진 결과물을 통해 하나처럼 보여진다.
	
	- 스키마 : 테이블에 접근하기 위한 권한, 권한을 가진 사람만 특정 해당 테이블에 접근할 수 있다. 데이터의 접근을 관리하는 기법, 통제하는 기법.
			종류는 논리 스키마와 물리 스키마가 있다.
		- 논리 스키마 : 가상 스키마. 실제 DB에는 없지만 가상으로 만들어 진 view 테이블, 논리모델은 dbms에 종속 x
		- 물리 스키마 : 실제 DB에 존재하는 물리적인 테이블, 물리모델은 dbms에 종속 o

- 업무데이터를 이해한다는 것
	- 누가, 언제, 어떤 상품을 어느 회사로부터 얼마에 구매했는가?
	- 선행관계, 종속성 규칙 등을 관찰

- 업무데이터 분석 과정
	- 업무의 이해 -> 업무 데이터의 이해 -> 데이터 구조 모델링 -> DB 생성

- 데이터 개념 필요성
	- 개념 데이터를 정의하지 않고 엔티티를 도출해서는 고품질의 데이터 모델을 작성할 수 없음
	- 명사를 대상으로 엔티티 정의에 맞는 것을 도출한다 하여도 후보 엔티티를 비슷한 성격으로 분류하고 통합하여 
	  일관된 사상을 갖는 모델을 효율적으로 작성하려면, Bottom-up으로 작업하기 전에 데이터 개념 정립이 필요함.

- FSDM(Financial Services Data model)
	- 핵심 내용
		- 금융기관의 데이터는 크게 9가지의 Data 개념(Concept)을 근간으로 함
		- 금융기관의 데이터는 9가지 Data 개념에 관한 데이터와 9가지 Data 개념간의 관계에 관한 정보로 구성 됨
		- 9가지 Data 개념에 관한 데이터는 Classification 정보와 Description 정보로 구성 됨
	
	- 9 Concept
		1. 이해 관계자(IP) : 
			- 금융기관과 접촉을 하고 관심이 있는 모든 당사자
		2. 계약(AR) :
			- 상품, 서비스 등의 가치를 교환하는데 관련된 룰이나 의무/권리를 나타내는 둘 이상의 개인이나 조직간의 잠재적, 실제적인 약정
		3. 조건(CD) :
			- 업무처리에 관한 구조화된 요건과 전제조건
		4. 상품(PD) : 
			- 금융기관이 제조, 판매하는 금융상품 또는 서비스
		5. 장소(LO) :
			- 금융기관이 정보를 유지하고자 하는 장소, 목적지, 또는 지역
		6. 분류(CL) : 
			- 특정한 업무정보를 분류하는 카테고리의 구조
		7. 경영방침/전략(BD) : 
			- 금융기관의 업무/재무 계획, 정책, 절차와 일정 등 업무를 수행하고자 하는 방식과 경영환경에 대한 관계당사자의 지침/전략
		8. 이벤트(EV) :
			- 업무 수행의 한 부분으로 데이터에 영향을 미치는 사건
		9. 자원(RI) :
			- 업무를 수행하는 동안 금융기관이 운영, 소유하거나 사용하는 유형/무형의 가치가 있는 것

* ITA (정보기술 아키텍처) : 범정부 ITA 통합관리 시스템

- 다시 Entity
	- 범주화(Classification)
	- 추상화(Abstraction)
	- CRM :
		CRM이란 Customer Relationship Management의 약자이며, 한국어로 고객 관계 관리를 뜻
		CRM은 매출과 직결되는 솔루션
		
	- Entity 모델링의 고충
		- 데이터 집합을 정의하기 쉽지 않다.
		- 데이터의 본질을 볼 줄 알아야 한다.
		- 추상화 수준의 결정
		- 하위 트랜잭션 데이터로 상위 논리집합 발견하기
	- 엔티티의 본질
		- 수학적 개념 : 엔티티는 집합이다.
		- 철학적 개념 : 엔티티는 본질이다.
		
- 속성 분석
	- 검토할 사항
		- 속성이 충분히 세분화되었는가?
		- 속성이 일관성 있고 배타적인 값을 갖는가?
		- 속성이 같은 어커런스에 대해 복수의 값들을 갖는가?
		- 복수 어커런스가 이 속성에 대해 같은 값을 갖는다면, 그 값들이 업무에 의미가 있는 것인가?
		- 이 속성이 도출 가능한 것이라면 그 값이 모든 어커런스에 적용 가능한 것인가?
	
	- 검토1 : 세분화
		- 속성이 충분히 세분화되었는가?
		- 분리가능 한 속성은 최대한 분리해야 함.
	- 검토2 : 배타성
		- 속성이 일관성 있고 배타적인 값을 갖는가?
		- 값의 배타성을 조사하여 배타적이지 않은 경우, 속성을 분리하여야 함
	- 검토3 : 시간의 흐름
		- 속성이 같은 어커런스에 대해 복수의 값들을 갖는가?
		- 특정 시간에?
		- 계속해서 변하는가? 과거의 기록이 중요한가?
		- 만약 그렇다면 별도의 엔티티로 도출하여야 한다.
	- 검토4 : 의미 있는 중복 값
		- 복수 어커런스가 이 속성에 대해 같은 값을 갖는다면, 그 값들이 업무에 의미가 있는 것인가?
		- 만약 그렇다면 별도의 엔티티로 분리하여야 함 
		예)엔티티 : 담보설정
	- 검토5 : 도출가능한 속성
		- 이 속성이 도출 가능한 것이라면 그 값이 모든 어커런스에 적용 가능한 것인가?
		- 도출 가능한 속성은 제외함
		
- 정규화(Normalization)
	- 정의 : 
		효율적인 관리를 위한 데이터구조를 도출하기 위하여, 속성간의 관계를 분석하여 별도 엔티티 도출 여부를 결정해 나가는 절차에 관련된 이론
	- 효과 :
		정규화의 기본 원칙은 하나의 테이블에는 중복된 데이터가 없도록 하는 것이며 효과는 다음과 같음
			- 데이터 중복에 따른 정합성 오류 발생가능성 제거
			- 성능 개선
	- 정규화 규칙
		- 효율적인 관리를 위한 데이터구조를 도출하기 위하여, 속성간의 관계를 분석하여 별도 엔티티 도출 여부를 결정해 나가는 절차에 관련된 이론
		- 제 1 정규화 : 반복 또는 복수 값을 갖는 속성의 제거, 반복되는 패턴을 찾는다.
			- 반복그룹의 속성을 별도의 엔티티로 분리가능
			- 작업 절차
				- 반복하는 속성 그룹으로 새로운 엔티티 작성
				- 새로운 엔티티 키(Concatenate Key) 및 관계를 정의
				
		- 제 2 정규화 : 기본키에 종속 되지 않는 속성의 제거(기본키의 일부에 종속되는 속성의 제거), 복합키가 있어야지만 정규화 가능
			- 기본키에 종속되지 않는 모든 속성을 분리하여 새로운 엔티티를 구성
			- 복합키(Concatenated Key)가 있는 엔티티에 적용됨
			- 작업 절차
				- 속성중에 Key의 일부에만 종속하는 속성을 분리
				- 새로운 엔티티를 정의한다.
				- 새로운 엔티티 키 및 관계를 정의
				
		- 제 3 정규화 : 기본키가 아닌 속성에 종속적인 속성의 제거  
			- 엔티티의 속성 중에 기본 키가 아닌 속성에 종속하는 모든 속성을 분리하여 새로운 엔티티를 생성
			- 작업 절차
				- 속성 중에 Key가 아닌 속성에 종속하는 속성을 분리한다.
				- 새로운 엔티티를 정의한다.
				- 새로운 엔티티 키 및 관계를 정의
				
- 메타데이터의 관리
	- 데이터 표준화
		- 표준화란? : 이음동의어와 동음이의어를 관리하는 것
	- 메타데이터란? :
		- 데이터들의 데이터
		- 통일시켜 일관되게 사용되도록 하는 것
		- 주로 데이터를 담는 최소 단위인 속성의 표준화
	- 메타관리 시스템에서 관리하는 수많은 시스템을 어떻게 통제할 것인가
	- 표준용어 : 표준 단어들의 조합, 복합어의 허용 제한 필요
	- * 인덱스(Index) : 데이터를 더 빨리 찾아오기 위해서 구조화 해놓은 것(색인)
	- 인덱스 기법 : 데이터를 적재할 때 무엇을 기준으로 적재할지?
	  예) 주민등록번호 오름차순 적재, 이름 가나다순 내림차순 적재
	- 컬럼마다 인덱스 기준으로 나누지 않는 이유는 메모리를 굉장히 많이 차지하기 때문
	- Full Scan : 인덱스를 잡는것 과는 상관없이 천만건이 있으면 정직하게 천만건을 다 탐색하는 것을 말한다.
	  예) 무식하게 하나하나 다 뒤져보는....쿼리속도가 아주 극악으로 떨어지는 결과를 초래한다.
	    (정렬이나 탐색방법을 통해서 빠르게 찾는방법을 이용해야지!)
	
	- 메타데이터 관리 시스템
	
	- 코드  
		- 코드인 것과 코드가 아닌 것, 식별자(보통 PK)와 식별자가 아닌 것을 구분해야 한다.
		- 코드 : 오직 릴레이션의 튜플들에 대해 특정 기준 중심의 분류 / 집합.
		- 표준화 : 식별자에는 ID나 번호, 코드에만 코드
		
	- 개별코드와 통합코드
		- 개별코드 :  유형만 관리, 일반화 가능
			- 코드가 하나 생길 때 마다 테이블, 엔티티를 하나씩 추가 해줘야함.
			- 코드가 날씬한 느낌
		- 통합코드 : 실체 관리
			- 코드가 하나 추가 되더라도 테이블이 추가되지 않고 엔티티에 한줄 추가.
			- 코드가 뚱뚱한(온갖 엔티티가 다 들어가 있으니까~) 느낌
			- 사용하는데 있어서 득과 실이 있으므로 사용에 고민해 보아야함.
		
		- 데이터를 통합 관리함으로써, 등록 / 참조 / 분배 등 관리상 장점
		- 코드 사용빈도가 하나의 테이블에 응집 - 메모리 성능상의 이점 기대
		- 어플리케이션 아키텍처를 고려한 선택 필요
		
- 모델링 프로세스 실무
	- 모델링 / 테이블 작성 프로세스
	
	* 형상관리 프로그램 : SVN, Git Hub
	
- 데이터의 품질관리
	- 품질관리의 기준
		- 모델링에는 정답이 없다. 평가 및 측정 또한 개발 후 운영되어지면서 증명
		- 현황에 대한 다양한 기준을 마련하여, 해당 기준 충족여부를 통해 품질 가늠
		- 모델링 품질 기준
			1. 표준화 관점 : 업무에서 결정된 표준항목의 준수 여부로 판단
				- 표준용어와 표준 도메인 사용여부 확인
				- 네이밍룰과 필수 입력항목의 준수여부 확인
			2. 모델링 방법론 관점 : 일반적인 모델링 룰의 준수 여부로 판단
				- 중복여부 확인
				- 관계선 지정 룰 준수 여부 확인
				- 인덱스 룰 확인
				- 정규화 여부 확인
			3. 업무적 관점 : 기업의 업무를 정확하게 표현했는지의 여부로 판단
				- 담당 업무 DA들에 의한 업무 표현의 정확도 확인
		
		- 역할별 품질관리의 범위
			- CIO / EDA (개괄적 관점)
			- DA (개념적 관점)
			- 모델러 (논리적 관점)
			- DBA (물리적 관점)
			- 사용자 (운용적 관점)

- 데이터모델링 도구
	- 데이터모델링 지원 툴
		- eXERD : 토마토 시스템
		- DA# : 엔코아
		- MS Visio : 그림그리는데 특화 된 툴

- 인증제도 
	- 한국데이터산업진흥원(K-data)에서 시행
	- 데이터 가치 증대를 위한 데이터 품질 / 관리 / 보안 체계에 대해 심사, 인증하는 제도
	- 인증대상
		- 데이터품질인증 : 유동, 활용, 개방 데이터의 품질 향상을 위한 인증
		- 데이터관리인증 : 효과적인 데이터 활용을 위한 데이터 거버넌스 정책, 데이터 관리 체계 인증
		- 데이터보안인증 : 데이터 보안 위협의 선제적인 대응과 안전한 데이터 비즈니스를 위한 인증
		
* 정보처리기사, SQLD 자격증 따라~ 꼭 따라~ *